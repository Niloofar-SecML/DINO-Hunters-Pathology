# -*- coding: utf-8 -*-
"""Untitled6(1)(2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18vUDkvmy8ldRzQ6vm_BIvcoEeb3gBdlG
"""

!pip install -q ultralytics timm torch torchvision pandas pillow matplotlib tifffile imagecodecs scikit-learn tqdm

import os, random, numpy as np, pandas as pd, tifffile as tiff
from pathlib import Path
from tqdm import tqdm
from PIL import Image
import torch, timm, matplotlib.pyplot as plt
from ultralytics import YOLO
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# ------------------------------------------------------------
# CONFIG
# ------------------------------------------------------------
EXCEL_PATH = "/content/drive/MyDrive/gmeruli.xlsx"
DATA_DIR   = "/content/drive/MyDrive/Converted"   # Folder with .ome.tif slides
YOLO_DIR   = "/content/drive/MyDrive/Glom_YOLOv8"
os.makedirs(YOLO_DIR, exist_ok=True)
device = "cuda" if torch.cuda.is_available() else "cpu"
print("‚ñ∂ Device:", device)

# Load Excel
df = pd.read_excel(EXCEL_PATH)
df = df.head(1000)
df["label"] = df["Type"].apply(lambda x: 1 if str(x).lower().strip()=="gs" else 0)
df["Glom_Index"] = df["Glom_Index"].fillna(0).astype(int)
df["split"] = df.apply(lambda _: "train" if random.random()<0.8 else "val", axis=1)

# Create YOLO directories
for s in ["train","val"]:
    os.makedirs(f"{YOLO_DIR}/images/{s}", exist_ok=True)
    os.makedirs(f"{YOLO_DIR}/labels/{s}", exist_ok=True)

# Convert Excel annotations ‚Üí YOLO .txt labels AND copy corresponding TIF images
count_valid = 0
import cv2

for _, row in df.iterrows():
    W,H = row["SVS_image_Width"], row["SVS_image_Height"]
    if pd.isna(W) or pd.isna(H): continue

    # Calculate normalized YOLO coordinates
    x_c,y_c = row["center_x"]/W, row["center_y"]/H
    w_n,h_n = row["Width"]/W, row["Height"]/H
    if not (0 <= x_c <= 1 and 0 <= y_c <= 1): continue

    # Find corresponding TIF file (exact name matching)
    folder_name = row['Folder_Name']
    tif_files = list(Path(DATA_DIR).glob(f"{folder_name}.tif")) + list(Path(DATA_DIR).glob(f"{folder_name}.tiff"))

    if tif_files:
        tif_path = tif_files[0]  # Take the first match

        try:
            # Load and convert TIF to JPG for YOLO
            tif_image = tiff.imread(str(tif_path))

            # Handle different TIF formats
            if len(tif_image.shape) == 3:
                if tif_image.shape[0] < tif_image.shape[2]:  # Channel first to channel last
                    tif_image = np.transpose(tif_image, (1, 2, 0))
                if tif_image.shape[2] > 3:  # Take first 3 channels if more than RGB
                    tif_image = tif_image[:, :, :3]
            else:
                # Convert grayscale to RGB
                tif_image = np.stack([tif_image] * 3, axis=-1)

            # Normalize to 0-255 range
            if tif_image.max() > 255:
                tif_image = ((tif_image - tif_image.min()) / (tif_image.max() - tif_image.min()) * 255).astype(np.uint8)
            else:
                tif_image = tif_image.astype(np.uint8)

            # Save as JPG for YOLO
            img_filename = f"{folder_name}_{row['Glom_Index']}.jpg"
            img_path = f"{YOLO_DIR}/images/{row['split']}/{img_filename}"

            # Convert RGB to BGR for OpenCV
            tif_image_bgr = cv2.cvtColor(tif_image, cv2.COLOR_RGB2BGR)
            cv2.imwrite(img_path, tif_image_bgr)

            # Create corresponding label file
            txt_path = f"{YOLO_DIR}/labels/{row['split']}/{folder_name}_{row['Glom_Index']}.txt"
            with open(txt_path, "w") as f:
                f.write(f"{row['label']} {x_c:.6f} {y_c:.6f} {w_n:.6f} {h_n:.6f}\n")

            count_valid += 1

        except Exception as e:
            print(f"‚ö†Ô∏è Error processing {tif_path}: {e}")
            continue
    else:
        print(f"‚ö†Ô∏è No TIF file found for {folder_name}")

print(f"‚úÖ Generated {count_valid} YOLO image-label pairs.")

# Debug: Check available TIF files and Excel data structure
print("üîç Debugging TIF files and Excel structure...")

# Check TIF files in DATA_DIR
tif_files = list(Path(DATA_DIR).glob("*.tif")) + list(Path(DATA_DIR).glob("*.tiff"))
print(f"üìÅ Found {len(tif_files)} TIF files in {DATA_DIR}:")
for i, tif_file in enumerate(tif_files[:5]):  # Show first 5
    print(f"   {i+1}. {tif_file.name}")
if len(tif_files) > 5:
    print(f"   ... and {len(tif_files)-5} more files")

# Check Excel data structure
print(f"\nüìä Excel data info:")
print(f"   Rows: {len(df)}")
print(f"   Columns: {list(df.columns)}")
print(f"\nüìã Sample folder names from Excel:")
sample_folders = df['Folder_Name'].unique()[:5]
for folder in sample_folders:
    print(f"   - {folder}")

# Check for missing coordinate columns
required_cols = ['center_x', 'center_y', 'Width', 'Height', 'SVS_image_Width', 'SVS_image_Height']
missing_cols = [col for col in required_cols if col not in df.columns]
if missing_cols:
    print(f"‚ö†Ô∏è Missing columns: {missing_cols}")
    print(f"üìã Available columns: {list(df.columns)}")
else:
    print("‚úÖ All required coordinate columns found")

print("\n" + "="*50)

yaml_path = f"{YOLO_DIR}/glom.yaml"
with open(yaml_path, "w") as f:
    f.write(f"""
train: {YOLO_DIR}/images/train
val: {YOLO_DIR}/images/val
nc: 2
names: ['non-GS','GS']
""")
print("‚úÖ Dataset YAML:", yaml_path)

# Verify YOLO dataset before training
def verify_yolo_dataset(yolo_dir):
    """Verify that images and labels are properly created"""
    train_imgs = len(list(Path(f"{yolo_dir}/images/train").glob("*.jpg")))
    val_imgs = len(list(Path(f"{yolo_dir}/images/val").glob("*.jpg")))
    train_labels = len(list(Path(f"{yolo_dir}/labels/train").glob("*.txt")))
    val_labels = len(list(Path(f"{yolo_dir}/labels/val").glob("*.txt")))

    print(f"üìä Dataset Verification:")
    print(f"   Training images: {train_imgs}")
    print(f"   Training labels: {train_labels}")
    print(f"   Validation images: {val_imgs}")
    print(f"   Validation labels: {val_labels}")

    if train_imgs == 0:
        print("‚ùå ERROR: No training images found!")
        return False
    elif train_imgs != train_labels:
        print("‚ö†Ô∏è WARNING: Mismatch between images and labels in training set")

    if val_imgs == 0:
        print("‚ùå ERROR: No validation images found!")
        return False
    elif val_imgs != val_labels:
        print("‚ö†Ô∏è WARNING: Mismatch between images and labels in validation set")

    print("‚úÖ Dataset verification passed!")
    return True

# Verify dataset
dataset_ok = verify_yolo_dataset(YOLO_DIR)

if not dataset_ok:
    print("‚ùå Dataset verification failed. Please check the TIF files and folder names.")
else:
    print("üéØ Ready for YOLO training!")

import tifffile as tiff
from PIL import Image
from tqdm import tqdm
import numpy as np

# Directory structure check
for s in ["train", "val"]:
    os.makedirs(f"{YOLO_DIR}/images/{s}", exist_ok=True)
    os.makedirs(f"{YOLO_DIR}/labels/{s}", exist_ok=True)

def crop_patch_from_tif_safe(slide_path, x1, y1, w, h, out_path):
    """Crop region safely from a .tif file, auto-clamping to image bounds."""
    with tiff.TiffFile(str(slide_path)) as tf:
        arr = tf.pages[0].asarray()

    H, W = arr.shape[:2]
    x1, y1 = int(max(0, x1)), int(max(0, y1))
    x2, y2 = int(min(W, x1 + w)), int(min(H, y1 + h))

    # Skip if invalid (zero-size crop)
    if x2 <= x1 or y2 <= y1:
        return False

    crop = arr[y1:y2, x1:x2]
    if crop.size == 0:
        return False

    # Normalize intensity safely
    crop = np.clip(crop, 0, np.percentile(crop, 99.9))
    m = np.max(crop)
    if m == 0 or np.isnan(m):
        return False
    crop = (crop / m * 255).astype(np.uint8)

    Image.fromarray(crop).convert("RGB").save(out_path)
    return True


print("üîß Generating YOLO training images from Excel (safe mode)...")
count, skipped = 0, 0

for _, row in tqdm(df.iterrows(), total=len(df)):
    folder = row["Folder_Name"]
    glom_idx = int(row["Glom_Index"])
    split = row["split"]

    tif_matches = list(Path(DATA_DIR).glob(f"{folder.replace('_seg','')}.tif"))
    if not tif_matches:
        skipped += 1
        continue

    tif_path = tif_matches[0]
    out_img = f"{YOLO_DIR}/images/{split}/{folder}_{glom_idx}.png"

    ok = crop_patch_from_tif_safe(
        tif_path,
        row["x1"], row["y1"],
        row["Width"], row["Height"],
        out_img
    )
    if ok:
        count += 1
    else:
        skipped += 1

print(f"‚úÖ Saved {count} cropped patches")

from ultralytics import YOLO
model = YOLO("yolov8n.pt")  # Start with small model
model.train(data=yaml_path, epochs=50, imgsz=512, val=False)
print("‚úÖ YOLOv8 trained for glomeruli detection.")

import torch, timm, numpy as np
from PIL import Image
from tqdm import tqdm

device = "cuda" if torch.cuda.is_available() else "cpu"

dino = timm.create_model("vit_small_patch14_dinov2", pretrained=True)
dino.eval().to(device)

@torch.no_grad()
def extract_dino_features(pil_image):
    """Safe universal DINO feature extractor."""
    pil_image = pil_image.resize((518, 518), Image.BICUBIC)
    arr = np.asarray(pil_image, dtype=np.float32) / 255.0
    arr = arr.transpose(2, 0, 1)  # HWC ‚Üí CHW
    x = torch.tensor(arr[None], dtype=torch.float32, device=device)

    feats = dino.forward_features(x)
    # Handle both tensor or dict outputs
    if isinstance(feats, dict):
        if "x_norm_clstoken" in feats:
            feats = feats["x_norm_clstoken"]
        elif "last_hidden_state" in feats:
            feats = feats["last_hidden_state"][:, 0, :]
        else:
            feats = list(feats.values())[0]
    elif isinstance(feats, torch.Tensor):
        feats = feats[:, 0, :] if feats.ndim == 3 else feats  # CLS token
    else:
        raise ValueError("Unexpected feature output type:", type(feats))

    return feats.cpu().numpy().flatten()

features, labels = [], []
for _, row in tqdm(df.iterrows(), total=len(df)):
    fname = f"{PATCH_DIR}/{row['Folder_Name']}_{int(row['Glom_Index'])}.png"
    if not os.path.exists(fname):
        continue
    try:
        img = Image.open(fname).convert("RGB")
        fvec = extract_dino_features(img)
        features.append(fvec)
        labels.append(row["label"])
    except Exception as e:
        print(f"‚ö†Ô∏è Skipped {fname}: {e}")
        continue

features = np.array(features)
labels = np.array(labels)
print("‚úÖ Feature matrix shape:", features.shape)

features = np.asarray(features)
labels = np.asarray(labels)

print("Samples:", features.shape, "Labels:", np.bincount(labels))

clf = LogisticRegression(max_iter=2000, class_weight="balanced")
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score
print("\n=== DINOv3 + Classifier Results")
print(classification_report(labels, y_pred, target_names=["non-GS", "GS"]))
print( "\naccuracy score: ",accuracy_score(labels, y_pred))
cm = confusion_matrix(labels, y_pred)
# disp = ConfusionMatrixDisplay(cm, display_labels=["non-GS", "GS"])
# ax = disp.plot(cmap="Blues")
# ax.figure_.suptitle("Confusion Matrix", fontsize=12)
# plt.show()

joblib.dump(clf, "/content/drive/MyDrive/dinov3_logreg.pkl")
print("\n‚úÖ Model saved to /content/drive/MyDrive/dinov3logreg.pkl")
